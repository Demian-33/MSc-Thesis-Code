\contentsline {chapter}{RESUMEN}{ii}{section*.1}%
\contentsline {chapter}{ABSTRACT}{iii}{section*.2}%
\contentsline {chapter}{LISTA DE FIGURAS}{x}{section*.4}%
\contentsline {chapter}{LISTA DE CUADROS}{xv}{section*.5}%
\contentsline {chapter}{\MakeUppercase []{CAPÍTULO 1.} \ INTRODUCCIÓN}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}Objetivos}{2}{section.1.1}%
\contentsline {section}{\numberline {1.2}Hipótesis}{3}{section.1.2}%
\contentsline {chapter}{\MakeUppercase []{CAPÍTULO 2.} \ REVISIÓN DE LITERATURA}{4}{chapter.2}%
\contentsline {section}{\numberline {2.1}Distribución normal asimétrica y truncamiento oculto}{4}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Distribución normal asimétrica}{5}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Distribución normal asimétrica multivariada}{7}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}Distribución normal asimétrica: parametrización centrada}{9}{subsection.2.1.3}%
\contentsline {subsection}{\numberline {2.1.4}Distribución normal asimétrica multivariada: parametrización centrada}{11}{subsection.2.1.4}%
\contentsline {subsection}{\numberline {2.1.5}Proceso de truncamiento oculto}{12}{subsection.2.1.5}%
\contentsline {subsection}{\numberline {2.1.6}Representación alternativa}{15}{subsection.2.1.6}%
\contentsline {section}{\numberline {2.2}Inferencia Bayesiana}{15}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Estimadores Bayesianos}{17}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Métodos de Monte Carlo}{18}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Cadenas de Markov en un espacio de estados general}{20}{subsection.2.2.3}%
\contentsline {subsection}{\numberline {2.2.4}Métodos Markov Chain Monte Carlo}{21}{subsection.2.2.4}%
\contentsline {subsection}{\numberline {2.2.5}Algoritmo Hamiltonian Monte Carlo}{22}{subsection.2.2.5}%
\contentsline {subsection}{\numberline {2.2.6}Ejemplo 1: aproximando una distribución normal bivariada}{25}{subsection.2.2.6}%
\contentsline {section}{\numberline {2.3}Inferencia Bayesiana variacional}{26}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Divergencia Kullback-Leibler}{28}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Ejemplo: divergencia KL entre las densidades normal y normal asimétrica}{29}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Límite inferior de la evidencia}{31}{subsection.2.3.3}%
\contentsline {subsection}{\numberline {2.3.4}Restricción Campo Medio}{33}{subsection.2.3.4}%
\contentsline {subsection}{\numberline {2.3.5}Algoritmo Inferencia Variacional por Ascenso de Coordenadas}{33}{subsection.2.3.5}%
\contentsline {subsection}{\numberline {2.3.6}Ejemplo 1: aproximando una distribución normal bivariada (revisitado)}{35}{subsection.2.3.6}%
\contentsline {subsection}{\numberline {2.3.7}Ejemplo 2: inferencia para la distribución normal}{37}{subsection.2.3.7}%
\contentsline {subsection}{\numberline {2.3.8}Ejemplo 3: inferencia para la distribución normal asimétrica}{42}{subsection.2.3.8}%
\contentsline {subsection}{\numberline {2.3.9}Restricción Forma Fija}{47}{subsection.2.3.9}%
\contentsline {subsection}{\numberline {2.3.10}Ejemplo 3: inferencia para la distribución normal asimétrica (revisitado)}{48}{subsection.2.3.10}%
\contentsline {subsection}{\numberline {2.3.11}ADVI: \textit {Automatic Differentiation Variational Inference}}{53}{subsection.2.3.11}%
\contentsline {subsubsection}{Aspectos del algoritmo ADVI}{58}{table.2.3}%
\contentsline {subsubsection}{Algoritmo ADVI}{61}{equation.2.71}%
\contentsline {chapter}{\MakeUppercase []{CAPÍTULO 3.} \ METODOLOGÍA}{63}{chapter.3}%
\contentsline {section}{\numberline {3.1}Descripción de los modelos en áreas pequeñas}{63}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}Modelo a nivel unidad con error anidado}{67}{subsection.3.1.1}%
\contentsline {section}{\numberline {3.2}Modelo log-normal sesgado}{71}{section.3.2}%
\contentsline {section}{\numberline {3.3}Modelo probit sesgado latente}{74}{section.3.3}%
\contentsline {section}{\numberline {3.4}Modelo probit ordenado sesgado latente}{78}{section.3.4}%
\contentsline {section}{\numberline {3.5}Distribución \textit {a priori} de referencia}{81}{section.3.5}%
\contentsline {section}{\numberline {3.6}Distribución \textit {a priori} para la búsqueda estocástica de variables}{85}{section.3.6}%
\contentsline {section}{\numberline {3.7}Distribución \textit {a posteriori}}{90}{section.3.7}%
\contentsline {section}{\numberline {3.8}Predicción de nuevas observaciones ($n_{i}>0$ y $n_{i}=0$)}{93}{section.3.8}%
\contentsline {section}{\numberline {3.9}Implementación con métodos \textit {Markov Chain Monte Carlo}}{95}{section.3.9}%
\contentsline {section}{\numberline {3.10}Implementación en {Stan}}{96}{section.3.10}%
\contentsline {subsection}{\numberline {3.10.1}Modelo log-normal sesgado centrado}{100}{subsection.3.10.1}%
\contentsline {subsection}{\numberline {3.10.2}Modelo probit ordenado sesgado latente centrado}{104}{subsection.3.10.2}%
\contentsline {subsection}{\numberline {3.10.3}Modelo probit sesgado latente centrado}{107}{subsection.3.10.3}%
\contentsline {section}{\numberline {3.11}Simulación y cantidades de interés}{107}{section.3.11}%
\contentsline {section}{\numberline {3.12}Caso de estudio: medición de la pobreza}{113}{section.3.12}%
\contentsline {subsection}{\numberline {3.12.1}Antecedentes}{114}{subsection.3.12.1}%
\contentsline {subsection}{\numberline {3.12.2}Fuentes de información y procesamiento}{116}{subsection.3.12.2}%
\contentsline {subsection}{\numberline {3.12.3}Ruta de trabajo}{118}{subsection.3.12.3}%
\contentsline {chapter}{\MakeUppercase []{CAPÍTULO 4.} \ RESULTADOS}{121}{chapter.4}%
\contentsline {section}{\numberline {4.1}Efecto de $\rho _{i}$ con $\mu _{i}$}{122}{section.4.1}%
\contentsline {section}{\numberline {4.2}Ajuste de los modelos de regresión sin reestricción en $\rho _{i}$}{123}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}Modelo log-normal sesgado}{124}{subsection.4.2.1}%
\contentsline {subsection}{\numberline {4.2.2}Modelo probit sesgado con variable latente}{124}{subsection.4.2.2}%
\contentsline {subsection}{\numberline {4.2.3}Modelo probit ordenado sesgado con variable latente}{125}{subsection.4.2.3}%
\contentsline {section}{\numberline {4.3}Ajuste del Modelo log-normal sesgado, datos simulados}{126}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}Modelos con interceptos en cada área pequeña}{126}{subsection.4.3.1}%
\contentsline {section}{\numberline {4.4}Ajuste del Modelo probit sesgado con variable latente, datos simulados}{130}{section.4.4}%
\contentsline {subsection}{\numberline {4.4.1}Modelos sin interceptos en cáda área pequeña}{130}{subsection.4.4.1}%
\contentsline {subsection}{\numberline {4.4.2}Modelos con interceptos en cada área pequeña}{133}{subsection.4.4.2}%
\contentsline {subsection}{\numberline {4.4.3}Modelos con único intercepto en todas las áreas pequeñas}{137}{subsection.4.4.3}%
\contentsline {section}{\numberline {4.5}Ajuste del Modelo probit ordenado sesgado con variable latente, datos simulados}{141}{section.4.5}%
\contentsline {subsection}{\numberline {4.5.1}Modelos sin interceptos en cáda área pequeña}{141}{subsection.4.5.1}%
\contentsline {subsection}{\numberline {4.5.2}Modelos con interceptos en cada área pequeña}{145}{subsection.4.5.2}%
\contentsline {subsection}{\numberline {4.5.3}Modelos con único intercepto en todas las áreas pequeñas}{148}{subsection.4.5.3}%
\contentsline {section}{\numberline {4.6}Análisis descriptivo del conjunto de datos del ICTPC}{151}{section.4.6}%
\contentsline {section}{\numberline {4.7}Ajuste del Modelo log-normal asimétrico, datos del ICTPC}{154}{section.4.7}%
\contentsline {subsection}{\numberline {4.7.1}Validación (entrenamiento-prueba)}{159}{subsection.4.7.1}%
\contentsline {subsection}{\numberline {4.7.2}Pronóstico de nuevas observaciones $(n_{i}=0)$}{160}{subsection.4.7.2}%
\contentsline {section}{\numberline {4.8}Ajuste del Modelo probit sesgado con variable latente, datos del ICTPC}{162}{section.4.8}%
\contentsline {subsection}{\numberline {4.8.1}Validación (entrenamiento-prueba)}{165}{subsection.4.8.1}%
\contentsline {section}{\numberline {4.9}Ajuste del Modelo probit ordenado sesgado con variable latente, datos del ICTPC}{166}{section.4.9}%
\contentsline {subsection}{\numberline {4.9.1}Validación (entrenamiento-prueba)}{170}{subsection.4.9.1}%
\contentsline {section}{\numberline {4.10}Estimaciones de $\beta $ en los tres modelos, datos del ICTPC}{170}{section.4.10}%
\contentsline {chapter}{\MakeUppercase []{CAPÍTULO 5.} \ DISCUSIÓN DE LOS RESULTADOS}{173}{chapter.5}%
\contentsline {section}{\numberline {5.1}Estudio de simulación}{173}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Interacción entre $\rho _{i}$ y $\mu _{i}$}{173}{subsection.5.1.1}%
\contentsline {subsection}{\numberline {5.1.2}Identificación de $\rho _{i}$}{173}{subsection.5.1.2}%
\contentsline {subsection}{\numberline {5.1.3}Modelo log-normal sesgado}{175}{subsection.5.1.3}%
\contentsline {subsection}{\numberline {5.1.4}Modelo probit sesgado latente}{175}{subsection.5.1.4}%
\contentsline {subsection}{\numberline {5.1.5}Modelo probit ordenado sesgado latente}{176}{subsection.5.1.5}%
\contentsline {section}{\numberline {5.2}Datos del ICTPC}{177}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}Modelo log-normal sesgado}{178}{subsection.5.2.1}%
\contentsline {subsection}{\numberline {5.2.2}Modelo probit sesgado latente}{179}{subsection.5.2.2}%
\contentsline {subsection}{\numberline {5.2.3}Modelo probit ordenado sesgado latente}{180}{subsection.5.2.3}%
\contentsline {chapter}{\MakeUppercase []{CAPÍTULO 6.} \ CONCLUSIONES Y RECOMENDACIONES}{181}{chapter.6}%
\contentsline {section}{\numberline {6.1}Recomendaciones}{183}{section.6.1}%
\contentsline {chapter}{ANEXOS}{190}{chapter*.131}%
\contentsline {section}{Anexo A}{190}{chapter*.132}%
\contentsline {section}{Anexo B}{204}{equation.6.20}%
\contentsline {section}{Anexo C}{205}{equation.6.20}%
\contentsline {section}{Anexo D}{209}{equation.6.20}%
